---
title: "Data Cleaning"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(pROC)
```

## Read in full dataset: 
```{r}
mexico <- read.csv("~/Documents/STA310/COVID-MortalityModel/201130COVID19MEXICO.csv")
dim(mexico)
```

## Restrict to 18-85 Year olds who are citizens of Mexico, only keep necessary columns
```{r}
names(mexico)
data <- filter(mexico, CLASIFICACION_FINAL == 3, EDAD >= 18 & EDAD <=85, NACIONALIDAD == 1)

data <- select(data, c("FECHA_DEF", "SEXO", "EDAD","INDIGENA", "DIABETES", "EPOC", "ASMA", "INMUSUPR", "HIPERTENSION", "OTRA_COM","CARDIOVASCULAR", "OBESIDAD", "RENAL_CRONICA", "TABAQUISMO"))
```

## Translate column names to English
```{r}
names(data)
colnames(data) <- c("DATE_DEATH", "SEX", "AGE", "INDIGENOUS", "DIABETES", "COPD", "ASTHMA", "IMMUNOSUPR", "HYPERTENSION", "OTHER_DIS", "CARDIOVASCULAR", "OBESITY", "CHRONIC_KIDNEY", "SMOKE")
```


## Change categorical variables to be 0, 1, or Na
```{r}
# Change explanatory variables
for (i in 2:14) {
  data[,i] <- case_when(data[,i] == 2 ~ 0,
                        data[,i] == 1 ~ 1,
                        data[,i] == 97 ~ NA_real_,
                        data[,i] == 98 ~ NA_real_,
                        data[,i] == 99 ~ NA_real_)
}

# Change response variable
data$DEATH <- ifelse(data$DATE_DEATH == "9999-99-99", 0, 1)
```

## Look at how many NA observations each unit has, use it to create NA/complete-observations datasets
```{r}
count.na <- apply(is.na(data), MARGIN = 1, sum)
table(count.na)
```

```{r}
na.Dataset <- data[count.na > 0, ]
complete.dataset <- data[count.na == 0,]
```
The proportions for all the variables in the original dataset are highly similar to the proportions in the dataset with only complete observations. We also found that interactions between multiple variables are also unaffected (i.e. Age and Death) by having or removing NAs. Therefore, we conclude that the dataset with only complete observations is largely representative of the original dataset, and thus by removing all rows that have an NA value for at least one variable, we are not introducing substantial bias. (See NAexploration.Rmd for full analysis).

## Remove all rows with at least one NA for downstream analysis
```{r}
data <- data[count.na==0,]
```

## Split data into testing and training set 
```{r}
## Split data into 50/50 for testing and training
set.seed(9)
inTrain <-  createDataPartition(y = data$DEATH, p = 0.5, list = F)
training <- data[inTrain, ]
testing <- data[-inTrain, ]
dim(training)
dim(testing)
```

## Building the best model without interaction terms
To start, we created a model with all of our 13 explanatory variables.
```{r}
all_nointeractions <- glm(DEATH~., "binomial", training)
summary(all_nointeractions)
```

We see that most variables have very small p-values and thus are likely important in the model. However, there are four variables with p-values higher than the rest: INDIGENOUS, ASTHMA, CARDIOVASCULAR, and SMOKE. So, we created a model without these four variables and then used a drop-in-deviance test see if these four variables make a significant difference to the model. 

```{r}
reduced_nointeractions <- glm(DEATH~.-CARDIOVASCULAR-INDIGENOUS-ASTHMA-SMOKE, "binomial", training)
summary(reduced_nointeractions)

full <-  all_nointeractions$deviance
reduced <- reduced_nointeractions$deviance

G <- reduced - full
df <- reduced_nointeractions$df.residual - all_nointeractions$df.residual

1-pchisq(G, df)
```

Here, we see that in the reduced model all explanatory variables have a p-value less than $2e^{-16}$. However, our drop-in-deviance test yields a p-value of 5.473951e-08, meaning we have evidence to reject the null hypothesis and conclude that at least one of the four variables we removed is important. Thus, we decide to include all of our explanatory variables in our model.

We also then used an ROC curve to assess the performance of our model with all explanatory variables. The AUC and ideal threshold to separate the people who died from those who survived based on the predicted probability are also included. This ideal threshold was found by finding the point where the sum of the sensitivity and specificity was highest.

```{r}
roc_all_nointeractions <- roc(response = training$DEATH, predictor=all_nointeractions$fitted.values,ci=F, plot=T, print.thres=T, print.auc=T, quiet = T, main="ROC Curve: All variables, no interaction terms")
```

## Investigating interaction terms 

```{r}
all_winteraction <- glm(DEATH~(.)^2, "binomial", training)
summary(all_winteraction)

## Drop - in - deviance test
G <-  all_nointeractions$deviance - all_winteraction$deviance 
df <- all_nointeractions$df.residual - all_winteraction$df.residual
1 - pchisq(G, df)

## ROC
roc(response = training$DEATH, predictor=all_winteraction$fitted.values,ci=F, plot=T)



## Reduced interaction
#We used a p-value cutoff of 0.0005 for significance (Adjusted Bonferroni)
interaction_reduced <- glm(data = training, DEATH ~ SEX + AGE + INDIGENOUS + DIABETES + COPD + ASTHMA + IMMUNOSUPR + HYPERTENSION + OTHER_DIS + CARDIOVASCULAR + OBESITY + CHRONIC_KIDNEY + SMOKE + SEX:AGE + SEX:DIABETES + SEX:HYPERTENSION + SEX:CHRONIC_KIDNEY + SEX:SMOKE + AGE:INDIGENOUS + AGE:DIABETES + AGE:COPD + AGE:IMMUNOSUPR + AGE:HYPERTENSION + AGE:OTHER_DIS + AGE:CARDIOVASCULAR + AGE:OBESITY + AGE:CHRONIC_KIDNEY + AGE:SMOKE + DIABETES:OBESITY + IMMUNOSUPR:CHRONIC_KIDNEY + HYPERTENSION:OBESITY + OTHER_DIS:OBESITY , family = "binomial")

# summary(interaction_reduced)

#Drop in deviance compared to no interactions 
G <-  all_nointeractions$deviance - interaction_reduced$deviance
df <- all_nointeractions$df.residual - interaction_reduced$df.residual
1 - pchisq(G, df)


#Drop in deviance compared to ALL interactions
G <-  interaction_reduced$deviance - all_winteraction$deviance
df <- interaction_reduced$df.residual - all_winteraction$df.residual
1 - pchisq(G, df)

#at least one of interactions we took out is significant 

roc_interaction_reduced <- roc(response = training$DEATH, predictor=interaction_reduced$fitted.values,ci=F, plot=T, print.thres=T, print.auc=T)




#AUC no interactions:   0.8538

#AUC some interactions: 0.8559

# AUC all interactions: 0.8562
```

## CONFUSION MATRICES
```{r}
#make confusion matrix for reduced interaction model using ideal threshold
predicted_interaction_reduced <- ifelse(interaction_reduced$fitted.values > 0.091, 1, 0)
table(predicted_interaction_reduced, training$DEATH)

# accuracy for reduced interaction
(331890+38938) / nrow(training)



# make confusion matrix for all-interactions model using ideal threshold
predicted_all_winteraction <- ifelse(all_winteraction$fitted.values > 0.091, 1, 0)
table(predicted_all_winteraction, training$DEATH)

# accuracy for all-interactions
(332356+38856) / nrow(training)
```


## PLOTS PLOTS PLOTS PLOTS PLOTS PLOTS PLOTS PLOTS PLOTS PLOTS PLOTS PLOTS PLOTS PLOTS PLOTS PLOTS (everybody!)

```{r}

Fits <- mutate(training, fit = interaction_reduced$fitted.values)

ggplot(data = Fits) +
  geom_line(aes(x = AGE, y = fit, color = as.factor(SEX)))

#We are going to have to do plots FOR things. FOR people with obesity...what happens.... (etc)
#As simple as possible
#Choosing some value for everything else, then go from there 

```




## Evaluating fit for testing data set
```{r}
predicted_testing <- predict(interaction_reduced, newdata = testing, type = "response")

roc_testing <- roc(response = testing$DEATH, predictor=predicted_testing,ci=F, plot=T, print.thres=T, print.auc=T)

predicted_testing_bestcutoff <- ifelse(predicted_testing > 0.091, 1, 0)
table(predicted_testing_bestcutoff, testing$DEATH)

kappa_testing <- ( (331514+38776) / nrow(testing) - ( (331514+117818)*(331514+8123) + (8123+38776)*(117818+38776) ) / nrow(testing)^2) / ( 1 - ( (331514+117818)*(331514+8123) + (8123+38776)*(117818+38776) ) / nrow(testing)^2)
```
